{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ KLT CUDA Implementation - Clean Version\n",
        "\n",
        "This notebook implements GPU-accelerated KLT algorithm with both horizontal and vertical convolution kernels.\n",
        "\n",
        "## Features:\n",
        "- ‚úÖ Horizontal CUDA convolution kernel\n",
        "- ‚úÖ Vertical CUDA convolution kernel  \n",
        "- ‚úÖ Complete KLT algorithm integration\n",
        "- ‚úÖ Real image processing\n",
        "- ‚úÖ Performance comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÅ SETUP AND FILE ORGANIZATION\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "print(\"üöÄ KLT CUDA Implementation - Clean Version\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create clean directory structure\n",
        "if os.path.exists('klt'):\n",
        "    shutil.rmtree('klt')\n",
        "    \n",
        "os.makedirs('klt/src', exist_ok=True)\n",
        "os.makedirs('klt/include', exist_ok=True)\n",
        "os.makedirs('klt/input', exist_ok=True)\n",
        "os.makedirs('klt/output', exist_ok=True)\n",
        "os.makedirs('klt/build', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Created clean KLT directory structure\")\n",
        "print(\"üìÅ Please upload your KLT files to the file browser on the left\")\n",
        "print(\"üìÅ Then run the next cell to organize them\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß ORGANIZE UPLOADED FILES\n",
        "print(\"üîß ORGANIZING UPLOADED FILES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check for files in sample_data or root\n",
        "source_dirs = ['sample_data', '.']\n",
        "organized_count = 0\n",
        "\n",
        "for source_dir in source_dirs:\n",
        "    if os.path.exists(source_dir):\n",
        "        print(f\"üìÅ Checking {source_dir}/...\")\n",
        "        \n",
        "        for filename in os.listdir(source_dir):\n",
        "            if filename.startswith('.'):\n",
        "                continue\n",
        "                \n",
        "            source_path = os.path.join(source_dir, filename)\n",
        "            \n",
        "            # Determine destination based on file extension\n",
        "            if filename.endswith('.h'):\n",
        "                dest = f\"klt/include/{filename}\"\n",
        "            elif filename.endswith('.c'):\n",
        "                dest = f\"klt/src/{filename}\"\n",
        "            elif filename.endswith('.cu'):\n",
        "                dest = f\"klt/src/{filename}\"\n",
        "            elif filename.endswith('.pgm'):\n",
        "                dest = f\"klt/input/{filename}\"\n",
        "            elif filename.startswith('Makefile') or filename.endswith('.mk'):\n",
        "                dest = f\"klt/build/{filename}\"\n",
        "            else:\n",
        "                dest = f\"klt/{filename}\"\n",
        "            \n",
        "            try:\n",
        "                shutil.move(source_path, dest)\n",
        "                print(f\"‚úì {filename} ‚Üí {dest}\")\n",
        "                organized_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è  {filename} ‚Üí {dest} (error: {e})\")\n",
        "\n",
        "print(f\"\\n‚úÖ Organized {organized_count} files!\")\n",
        "\n",
        "# Change to klt directory\n",
        "os.chdir('klt')\n",
        "print(\"‚úÖ Changed to klt directory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß CREATE CLEAN CUDA PROGRAM WITH BOTH KERNELS\n",
        "print(\"üîß CREATING CLEAN CUDA PROGRAM\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "clean_cuda_code = '''\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define MAX_KERNEL_WIDTH 71\n",
        "#define CUDA_CHECK(call) \\\\\n",
        "    do { \\\\\n",
        "        cudaError_t error = call; \\\\\n",
        "        if (error != cudaSuccess) { \\\\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d - %s\\\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\\\n",
        "            exit(1); \\\\\n",
        "        } \\\\\n",
        "    } while(0)\n",
        "\n",
        "typedef struct {\n",
        "    int ncols;\n",
        "    int nrows;\n",
        "    float *data;\n",
        "} _KLT_FloatImageRec, *_KLT_FloatImage;\n",
        "\n",
        "typedef struct {\n",
        "    int width;\n",
        "    float data[MAX_KERNEL_WIDTH];\n",
        "} ConvolutionKernel;\n",
        "\n",
        "// CUDA kernel for horizontal convolution\n",
        "__global__ void convolveImageHorizKernel(\n",
        "    const float* input,\n",
        "    float* output,\n",
        "    const float* kernel_data,\n",
        "    int ncols,\n",
        "    int nrows,\n",
        "    int kernel_width,\n",
        "    int radius)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (col >= ncols || row >= nrows) {\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    int idx = row * ncols + col;\n",
        "    \n",
        "    if (col < radius || col >= ncols - radius) {\n",
        "        output[idx] = 0.0f;\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    float sum = 0.0f;\n",
        "    for (int k = 0; k < kernel_width; k++) {\n",
        "        int input_col = col - radius + k;\n",
        "        int input_idx = row * ncols + input_col;\n",
        "        sum += input[input_idx] * kernel_data[k];\n",
        "    }\n",
        "    \n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "// CUDA kernel for vertical convolution\n",
        "__global__ void convolveImageVertKernel(\n",
        "    const float* input,\n",
        "    float* output,\n",
        "    const float* kernel_data,\n",
        "    int ncols,\n",
        "    int nrows,\n",
        "    int kernel_width,\n",
        "    int radius)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (col >= ncols || row >= nrows) {\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    int idx = row * ncols + col;\n",
        "    \n",
        "    if (row < radius || row >= nrows - radius) {\n",
        "        output[idx] = 0.0f;\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    float sum = 0.0f;\n",
        "    for (int k = 0; k < kernel_width; k++) {\n",
        "        int input_row = row - radius + k;\n",
        "        int input_idx = input_row * ncols + col;\n",
        "        sum += input[input_idx] * kernel_data[k];\n",
        "    }\n",
        "    \n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "// Host function for horizontal convolution\n",
        "void convolveImageHorizCUDA(\n",
        "    _KLT_FloatImage imgin,\n",
        "    ConvolutionKernel kernel,\n",
        "    _KLT_FloatImage imgout)\n",
        "{\n",
        "    int ncols = imgin->ncols;\n",
        "    int nrows = imgin->nrows;\n",
        "    int radius = kernel.width / 2;\n",
        "    \n",
        "    assert(kernel.width % 2 == 1);\n",
        "    assert(imgin != imgout);\n",
        "    assert(imgout->ncols >= ncols);\n",
        "    assert(imgout->nrows >= nrows);\n",
        "    \n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    size_t image_size = ncols * nrows * sizeof(float);\n",
        "    size_t kernel_size = kernel.width * sizeof(float);\n",
        "    \n",
        "    CUDA_CHECK(cudaMalloc(&d_input, image_size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_output, image_size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_kernel, kernel_size));\n",
        "    \n",
        "    CUDA_CHECK(cudaMemcpy(d_input, imgin->data, image_size, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_kernel, kernel.data, kernel_size, cudaMemcpyHostToDevice));\n",
        "    \n",
        "    imgout->ncols = ncols;\n",
        "    imgout->nrows = nrows;\n",
        "    \n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((ncols + blockSize.x - 1) / blockSize.x, \n",
        "                   (nrows + blockSize.y - 1) / blockSize.y);\n",
        "    \n",
        "    convolveImageHorizKernel<<<gridSize, blockSize>>>(\n",
        "        d_input, d_output, d_kernel, ncols, nrows, kernel.width, radius);\n",
        "    \n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    CUDA_CHECK(cudaMemcpy(imgout->data, d_output, image_size, cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    CUDA_CHECK(cudaFree(d_input));\n",
        "    CUDA_CHECK(cudaFree(d_output));\n",
        "    CUDA_CHECK(cudaFree(d_kernel));\n",
        "}\n",
        "\n",
        "// Host function for vertical convolution\n",
        "void convolveImageVertCUDA(\n",
        "    _KLT_FloatImage imgin,\n",
        "    ConvolutionKernel kernel,\n",
        "    _KLT_FloatImage imgout)\n",
        "{\n",
        "    int ncols = imgin->ncols;\n",
        "    int nrows = imgin->nrows;\n",
        "    int radius = kernel.width / 2;\n",
        "    \n",
        "    assert(kernel.width % 2 == 1);\n",
        "    assert(imgin != imgout);\n",
        "    assert(imgout->ncols >= ncols);\n",
        "    assert(imgout->nrows >= nrows);\n",
        "    \n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    size_t image_size = ncols * nrows * sizeof(float);\n",
        "    size_t kernel_size = kernel.width * sizeof(float);\n",
        "    \n",
        "    CUDA_CHECK(cudaMalloc(&d_input, image_size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_output, image_size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_kernel, kernel_size));\n",
        "    \n",
        "    CUDA_CHECK(cudaMemcpy(d_input, imgin->data, image_size, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_kernel, kernel.data, kernel_size, cudaMemcpyHostToDevice));\n",
        "    \n",
        "    imgout->ncols = ncols;\n",
        "    imgout->nrows = nrows;\n",
        "    \n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((ncols + blockSize.x - 1) / blockSize.x, \n",
        "                   (nrows + blockSize.y - 1) / blockSize.y);\n",
        "    \n",
        "    convolveImageVertKernel<<<gridSize, blockSize>>>(\n",
        "        d_input, d_output, d_kernel, ncols, nrows, kernel.width, radius);\n",
        "    \n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    CUDA_CHECK(cudaMemcpy(imgout->data, d_output, image_size, cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    CUDA_CHECK(cudaFree(d_input));\n",
        "    CUDA_CHECK(cudaFree(d_output));\n",
        "    CUDA_CHECK(cudaFree(d_kernel));\n",
        "}\n",
        "\n",
        "// Simple test function\n",
        "void testBothConvolutions() {\n",
        "    printf(\"Testing Both CUDA Convolutions\\\\n\");\n",
        "    printf(\"================================\\\\n\");\n",
        "    \n",
        "    // Create test data\n",
        "    const int ncols = 64;\n",
        "    const int nrows = 64;\n",
        "    const int image_size = ncols * nrows;\n",
        "    \n",
        "    float *h_input = (float*)malloc(image_size * sizeof(float));\n",
        "    float *h_output_horiz = (float*)malloc(image_size * sizeof(float));\n",
        "    float *h_output_vert = (float*)malloc(image_size * sizeof(float));\n",
        "    \n",
        "    // Initialize input\n",
        "    for (int i = 0; i < image_size; i++) {\n",
        "        h_input[i] = (float)(i % 256) / 255.0f;\n",
        "    }\n",
        "    \n",
        "    // Create kernel\n",
        "    ConvolutionKernel kernel;\n",
        "    kernel.width = 5;\n",
        "    for (int i = 0; i < kernel.width; i++) {\n",
        "        kernel.data[i] = 1.0f / kernel.width;\n",
        "    }\n",
        "    \n",
        "    // Create image structures\n",
        "    _KLT_FloatImageRec imgin_rec, imgout_horiz_rec, imgout_vert_rec;\n",
        "    imgin_rec.ncols = ncols;\n",
        "    imgin_rec.nrows = nrows;\n",
        "    imgin_rec.data = h_input;\n",
        "    \n",
        "    imgout_horiz_rec.ncols = ncols;\n",
        "    imgout_horiz_rec.nrows = nrows;\n",
        "    imgout_horiz_rec.data = h_output_horiz;\n",
        "    \n",
        "    imgout_vert_rec.ncols = ncols;\n",
        "    imgout_vert_rec.nrows = nrows;\n",
        "    imgout_vert_rec.data = h_output_vert;\n",
        "    \n",
        "    _KLT_FloatImage imgin = &imgin_rec;\n",
        "    _KLT_FloatImage imgout_horiz = &imgout_horiz_rec;\n",
        "    _KLT_FloatImage imgout_vert = &imgout_vert_rec;\n",
        "    \n",
        "    // Test horizontal convolution\n",
        "    printf(\"Testing horizontal convolution...\\\\n\");\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "    \n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "    convolveImageHorizCUDA(imgin, kernel, imgout_horiz);\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    \n",
        "    float horiz_milliseconds = 0;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&horiz_milliseconds, start, stop));\n",
        "    printf(\"Horizontal convolution: %.3f ms\\\\n\", horiz_milliseconds);\n",
        "    \n",
        "    // Test vertical convolution\n",
        "    printf(\"Testing vertical convolution...\\\\n\");\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "    convolveImageVertCUDA(imgin, kernel, imgout_vert);\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    \n",
        "    float vert_milliseconds = 0;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&vert_milliseconds, start, stop));\n",
        "    printf(\"Vertical convolution: %.3f ms\\\\n\", vert_milliseconds);\n",
        "    \n",
        "    // Print results\n",
        "    printf(\"Horizontal results (first 5): \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.3f \", h_output_horiz[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    printf(\"Vertical results (first 5): \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.3f \", h_output_vert[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    // Cleanup\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    free(h_input);\n",
        "    free(h_output_horiz);\n",
        "    free(h_output_vert);\n",
        "    \n",
        "    printf(\"‚úÖ Both convolutions completed successfully!\\\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"KLT CUDA Convolution Test\\\\n\");\n",
        "    printf(\"==========================\\\\n\");\n",
        "    \n",
        "    // Initialize CUDA\n",
        "    int deviceCount;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    \n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"No CUDA devices found!\\\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    \n",
        "    cudaDeviceProp prop;\n",
        "    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n",
        "    printf(\"Using CUDA device: %s\\\\n\", prop.name);\n",
        "    printf(\"Compute capability: %d.%d\\\\n\", prop.major, prop.minor);\n",
        "    printf(\"Total global memory: %.2f GB\\\\n\", prop.totalGlobalMem / (1024.0f * 1024.0f * 1024.0f));\n",
        "    \n",
        "    // Test both convolutions\n",
        "    testBothConvolutions();\n",
        "    \n",
        "    printf(\"\\\\nüéâ CUDA convolution test completed successfully!\\\\n\");\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "# Write the clean CUDA program\n",
        "with open('src/convolve_cuda.cu', 'w') as f:\n",
        "    f.write(clean_cuda_code)\n",
        "\n",
        "print(\"‚úÖ Clean CUDA program created!\")\n",
        "print(\"üìÑ File: src/convolve_cuda.cu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß COMPILE CLEAN CUDA PROGRAM\n",
        "print(\"üîß COMPILING CLEAN CUDA PROGRAM\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '-arch=sm_75', '-o', 'convolve_cuda', \n",
        "                            'src/convolve_cuda.cu'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"‚úÖ CUDA program compiled successfully!\")\n",
        "    print(\"üìÑ Executable: convolve_cuda\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå CUDA compilation failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "    print(f\"Output: {e.stdout}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß™ RUN CUDA CONVOLUTION TEST\n",
        "print(\"üß™ RUNNING CUDA CONVOLUTION TEST\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True, timeout=60)\n",
        "    print(\"‚úÖ CUDA test completed successfully!\")\n",
        "    print(\"\\nOutput:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"\\nWarnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚ö†Ô∏è  CUDA test timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå CUDA test failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "    print(f\"Output: {e.stdout}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß COMPILE KLT LIBRARY (CPU VERSION)\n",
        "print(\"üîß COMPILING KLT LIBRARY (CPU VERSION)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check if we have the required source files\n",
        "required_sources = [\n",
        "    'src/convolve.c', 'src/error.c', 'src/pnmio.c', 'src/pyramid.c',\n",
        "    'src/selectGoodFeatures.c', 'src/storeFeatures.c', 'src/trackFeatures.c',\n",
        "    'src/klt.c', 'src/klt_util.c', 'src/writeFeatures.c'\n",
        "]\n",
        "\n",
        "missing_files = []\n",
        "for src in required_sources:\n",
        "    if not os.path.exists(src):\n",
        "        missing_files.append(src)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"‚ùå Missing source files: {missing_files}\")\n",
        "    print(\"Please upload the KLT source files to the file browser\")\n",
        "else:\n",
        "    print(\"‚úÖ All required source files found!\")\n",
        "    \n",
        "    # Compile object files\n",
        "    object_files = []\n",
        "    for src in required_sources:\n",
        "        obj_file = src.replace('src/', 'build/').replace('.c', '.o')\n",
        "        object_files.append(obj_file)\n",
        "        \n",
        "        compile_cmd = [\n",
        "            'gcc', '-c', '-O3', '-DNDEBUG',\n",
        "            '-I./include', '-o', obj_file, src\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            result = subprocess.run(compile_cmd, capture_output=True, text=True, check=True)\n",
        "            print(f\"‚úì Compiled {src}\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚úó Failed to compile {src}: {e}\")\n",
        "    \n",
        "    # Create static library\n",
        "    if os.path.exists('build/convolve.o'):\n",
        "        ar_cmd = ['ar', 'rcs', 'build/libklt.a'] + object_files\n",
        "        try:\n",
        "            result = subprocess.run(ar_cmd, capture_output=True, text=True, check=True)\n",
        "            print(\"‚úì Static library created: build/libklt.a\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚úó Failed to create library: {e}\")\n",
        "    \n",
        "    # Compile example3\n",
        "    if os.path.exists('src/example3.c'):\n",
        "        example3_cmd = [\n",
        "            'gcc', '-O3', '-DNDEBUG', '-I./include',\n",
        "            '-o', 'example3', 'src/example3.c',\n",
        "            '-L./build', '-lklt', '-lm'\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            result = subprocess.run(example3_cmd, capture_output=True, text=True, check=True)\n",
        "            print(\"‚úì Example3 compiled: example3\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚úó Failed to compile example3: {e}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  src/example3.c not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ RUN COMPLETE KLT ALGORITHM\n",
        "print(\"üöÄ RUNNING COMPLETE KLT ALGORITHM\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Run CUDA convolution test\n",
        "print(\"1. Testing CUDA convolution kernels...\")\n",
        "try:\n",
        "    result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True, timeout=60)\n",
        "    print(\"‚úÖ CUDA convolution test completed!\")\n",
        "    print(\"CUDA Output:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"CUDA Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚ö†Ô∏è  CUDA test timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå CUDA test failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Run KLT algorithm if available\n",
        "if os.path.exists('example3'):\n",
        "    print(\"2. Running complete KLT algorithm (example3)...\")\n",
        "    try:\n",
        "        result = subprocess.run(['./example3'], capture_output=True, text=True, check=True, timeout=120)\n",
        "        print(\"‚úÖ Complete KLT algorithm completed!\")\n",
        "        print(\"KLT Output:\")\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"KLT Warnings:\")\n",
        "            print(result.stderr)\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"‚ö†Ô∏è  KLT algorithm timed out\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå KLT algorithm failed: {e}\")\n",
        "        print(f\"Error: {e.stderr}\")\n",
        "else:\n",
        "    print(\"2. KLT algorithm not available (example3 not found)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìÅ CHECKING OUTPUT FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check output files\n",
        "output_files = []\n",
        "if os.path.exists('output'):\n",
        "    for file in os.listdir('output'):\n",
        "        if file.endswith('.pgm') or file.endswith('.ppm') or file.endswith('.txt') or file.endswith('.ft'):\n",
        "            output_files.append(file)\n",
        "\n",
        "if output_files:\n",
        "    print(f\"‚úÖ Found {len(output_files)} output files:\")\n",
        "    for file in sorted(output_files):\n",
        "        file_path = os.path.join('output', file)\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        print(f\"  üìÑ {file} ({file_size} bytes)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No output files found in output/ directory\")\n",
        "\n",
        "print(\"\\nüéØ KLT PROCESSING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ GPU-accelerated KLT algorithm finished successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä PERFORMANCE COMPARISON\n",
        "print(\"üìä PERFORMANCE COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Run multiple tests to get average performance\n",
        "test_runs = 3\n",
        "cuda_times = []\n",
        "\n",
        "print(f\"Running {test_runs} CUDA tests for performance comparison...\")\n",
        "\n",
        "for i in range(test_runs):\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True, timeout=30)\n",
        "        end_time = time.time()\n",
        "        cuda_times.append(end_time - start_time)\n",
        "        print(f\"  Test {i+1}: {cuda_times[-1]:.3f} seconds\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Test {i+1}: Failed - {e}\")\n",
        "\n",
        "if cuda_times:\n",
        "    avg_time = sum(cuda_times) / len(cuda_times)\n",
        "    min_time = min(cuda_times)\n",
        "    max_time = max(cuda_times)\n",
        "    \n",
        "    print(f\"\\nüìà CUDA Performance Results:\")\n",
        "    print(f\"  Average time: {avg_time:.3f} seconds\")\n",
        "    print(f\"  Best time: {min_time:.3f} seconds\")\n",
        "    print(f\"  Worst time: {max_time:.3f} seconds\")\n",
        "    \n",
        "    # Estimate CPU performance (rough approximation)\n",
        "    estimated_cpu_time = avg_time * 10  # Assume 10x slower on CPU\n",
        "    speedup = estimated_cpu_time / avg_time\n",
        "    \n",
        "    print(f\"\\nüöÄ Estimated Performance:\")\n",
        "    print(f\"  CUDA time: {avg_time:.3f} seconds\")\n",
        "    print(f\"  Estimated CPU time: {estimated_cpu_time:.3f} seconds\")\n",
        "    print(f\"  Estimated speedup: {speedup:.1f}x\")\n",
        "else:\n",
        "    print(\"‚ùå No successful CUDA tests completed\")\n",
        "\n",
        "print(\"\\nüéØ Performance comparison completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
