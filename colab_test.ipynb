{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KLT CUDA Convolution Test\n",
        "\n",
        "This notebook tests the CUDA implementation of the horizontal convolution function from the KLT algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix nested klt/klt/ structure and show file structure\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def show_tree(directory, prefix=\"\", max_depth=3, current_depth=0):\n",
        "    \"\"\"Display directory structure like 'tree' command\"\"\"\n",
        "    if current_depth >= max_depth:\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        items = sorted(os.listdir(directory))\n",
        "        dirs = [item for item in items if os.path.isdir(os.path.join(directory, item))]\n",
        "        files = [item for item in items if os.path.isfile(os.path.join(directory, item))]\n",
        "        \n",
        "        # Show directories first\n",
        "        for i, item in enumerate(dirs):\n",
        "            is_last_dir = (i == len(dirs) - 1) and len(files) == 0\n",
        "            print(f\"{prefix}{'└── ' if is_last_dir else '├── '}{item}/\")\n",
        "            \n",
        "            # Recursively show subdirectories\n",
        "            next_prefix = prefix + (\"    \" if is_last_dir else \"│   \")\n",
        "            show_tree(os.path.join(directory, item), next_prefix, max_depth, current_depth + 1)\n",
        "        \n",
        "        # Show files\n",
        "        for i, item in enumerate(files):\n",
        "            is_last = i == len(files) - 1\n",
        "            print(f\"{prefix}{'└── ' if is_last else '├── '}{item}\")\n",
        "            \n",
        "    except PermissionError:\n",
        "        print(f\"{prefix}[Permission Denied]\")\n",
        "\n",
        "print(\"🔧 FIXING NESTED KLT STRUCTURE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check if we have the nested klt/klt/ structure\n",
        "if os.path.exists('klt/klt'):\n",
        "    print(\"⚠️  Found nested klt/klt/ structure - fixing...\")\n",
        "    \n",
        "    # Move files from klt/klt/ to klt/\n",
        "    nested_dirs = ['src', 'include', 'input', 'output', 'build', 'doc', 'matlab_interface']\n",
        "    \n",
        "    for dir_name in nested_dirs:\n",
        "        nested_path = f'klt/klt/{dir_name}'\n",
        "        target_path = f'klt/{dir_name}'\n",
        "        \n",
        "        if os.path.exists(nested_path):\n",
        "            # Remove target if it exists\n",
        "            if os.path.exists(target_path):\n",
        "                shutil.rmtree(target_path)\n",
        "            \n",
        "            # Move nested directory to correct location\n",
        "            shutil.move(nested_path, target_path)\n",
        "            print(f\"✓ Moved klt/klt/{dir_name}/ → klt/{dir_name}/\")\n",
        "    \n",
        "    # Remove empty nested klt directory\n",
        "    try:\n",
        "        os.rmdir('klt/klt')\n",
        "        print(\"✓ Removed empty nested klt/klt/ directory\")\n",
        "    except:\n",
        "        print(\"⚠️  Could not remove klt/klt/ directory (not empty)\")\n",
        "    \n",
        "    print(\"✅ Fixed nested structure!\")\n",
        "else:\n",
        "    print(\"✅ No nested structure found\")\n",
        "\n",
        "print(\"\\n🌳 CURRENT FILE STRUCTURE\")\n",
        "print(\"=\" * 60)\n",
        "show_tree(\".\", max_depth=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick fix for nested directories\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"🔧 QUICK FIX FOR NESTED DIRECTORIES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Fix nested src directory\n",
        "if os.path.exists('klt/src/src'):\n",
        "    print(\"📁 Fixing nested src/src/ structure...\")\n",
        "    for file in os.listdir('klt/src/src'):\n",
        "        src_path = f'klt/src/src/{file}'\n",
        "        dst_path = f'klt/src/{file}'\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"✓ Moved {file} → klt/src/\")\n",
        "    \n",
        "    # Remove the nested directory (handle non-empty case)\n",
        "    try:\n",
        "        os.rmdir('klt/src/src')\n",
        "        print(\"✅ Removed empty klt/src/src/ directory\")\n",
        "    except OSError:\n",
        "        # If not empty, remove all contents first\n",
        "        shutil.rmtree('klt/src/src')\n",
        "        print(\"✅ Removed klt/src/src/ directory and contents\")\n",
        "    print(\"✅ Fixed src/ directory\")\n",
        "\n",
        "# Fix nested include directory  \n",
        "if os.path.exists('klt/include/include'):\n",
        "    print(\"📁 Fixing nested include/include/ structure...\")\n",
        "    for file in os.listdir('klt/include/include'):\n",
        "        src_path = f'klt/include/include/{file}'\n",
        "        dst_path = f'klt/include/{file}'\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"✓ Moved {file} → klt/include/\")\n",
        "    \n",
        "    # Remove the nested directory (handle non-empty case)\n",
        "    try:\n",
        "        os.rmdir('klt/include/include')\n",
        "        print(\"✅ Removed empty klt/include/include/ directory\")\n",
        "    except OSError:\n",
        "        shutil.rmtree('klt/include/include')\n",
        "        print(\"✅ Removed klt/include/include/ directory and contents\")\n",
        "    print(\"✅ Fixed include/ directory\")\n",
        "\n",
        "# Fix nested input directory\n",
        "if os.path.exists('klt/input/input'):\n",
        "    print(\"📁 Fixing nested input/input/ structure...\")\n",
        "    for file in os.listdir('klt/input/input'):\n",
        "        src_path = f'klt/input/input/{file}'\n",
        "        dst_path = f'klt/input/{file}'\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"✓ Moved {file} → klt/input/\")\n",
        "    \n",
        "    # Remove the nested directory (handle non-empty case)\n",
        "    try:\n",
        "        os.rmdir('klt/input/input')\n",
        "        print(\"✅ Removed empty klt/input/input/ directory\")\n",
        "    except OSError:\n",
        "        shutil.rmtree('klt/input/input')\n",
        "        print(\"✅ Removed klt/input/input/ directory and contents\")\n",
        "    print(\"✅ Fixed input/ directory\")\n",
        "\n",
        "# Fix nested build directory\n",
        "if os.path.exists('klt/build/build'):\n",
        "    print(\"📁 Fixing nested build/build/ structure...\")\n",
        "    for file in os.listdir('klt/build/build'):\n",
        "        src_path = f'klt/build/build/{file}'\n",
        "        dst_path = f'klt/build/{file}'\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"✓ Moved {file} → klt/build/\")\n",
        "    \n",
        "    # Remove the nested directory (handle non-empty case)\n",
        "    try:\n",
        "        os.rmdir('klt/build/build')\n",
        "        print(\"✅ Removed empty klt/build/build/ directory\")\n",
        "    except OSError:\n",
        "        shutil.rmtree('klt/build/build')\n",
        "        print(\"✅ Removed klt/build/build/ directory and contents\")\n",
        "    print(\"✅ Fixed build/ directory\")\n",
        "\n",
        "# Fix nested output directory\n",
        "if os.path.exists('klt/output/output'):\n",
        "    print(\"📁 Fixing nested output/output/ structure...\")\n",
        "    for file in os.listdir('klt/output/output'):\n",
        "        src_path = f'klt/output/output/{file}'\n",
        "        dst_path = f'klt/output/{file}'\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"✓ Moved {file} → klt/output/\")\n",
        "    \n",
        "    # Remove the nested directory (handle non-empty case)\n",
        "    try:\n",
        "        os.rmdir('klt/output/output')\n",
        "        print(\"✅ Removed empty klt/output/output/ directory\")\n",
        "    except OSError:\n",
        "        shutil.rmtree('klt/output/output')\n",
        "        print(\"✅ Removed klt/output/output/ directory and contents\")\n",
        "    print(\"✅ Fixed output/ directory\")\n",
        "\n",
        "print(\"\\n🎯 VERIFICATION - Checking critical files:\")\n",
        "critical_files = [\n",
        "    'klt/src/convolve_cuda.cu',\n",
        "    'klt/include/klt.h',\n",
        "    'klt/include/base.h',\n",
        "    'klt/include/error.h',\n",
        "    'klt/src/example3.c',\n",
        "    'klt/src/convolve.c',\n",
        "    'klt/src/error.c'\n",
        "]\n",
        "\n",
        "all_found = True\n",
        "for file_path in critical_files:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"✅ {file_path}\")\n",
        "    else:\n",
        "        print(f\"❌ {file_path} - MISSING!\")\n",
        "        all_found = False\n",
        "\n",
        "if all_found:\n",
        "    print(\"\\n🎉 All critical files found! Ready to compile!\")\n",
        "else:\n",
        "    print(\"\\n⚠️  Some files are still missing. Check the structure above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check CUDA availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA capability: {torch.cuda.get_device_capability(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify manually organized KLT files for CUDA implementation\n",
        "import os\n",
        "\n",
        "print(\"🚀 KLT CUDA Implementation - Manual Organization\")\n",
        "print(\"=\" * 60)\n",
        "print(\"✅ Using manually organized files - skipping auto-organization\")\n",
        "print()\n",
        "\n",
        "# Verify critical files\n",
        "print(\"🔍 Checking for critical files...\")\n",
        "critical_files = [\n",
        "    'klt/src/convolve_cuda.cu',\n",
        "    'klt/include/klt.h', \n",
        "    'klt/include/base.h',\n",
        "    'klt/include/error.h',\n",
        "    'klt/src/example3.c',\n",
        "    'klt/src/convolve.c',\n",
        "    'klt/src/error.c'\n",
        "]\n",
        "\n",
        "missing_files = []\n",
        "found_files = []\n",
        "\n",
        "for file_path in critical_files:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"✓ {file_path}\")\n",
        "        found_files.append(file_path)\n",
        "    else:\n",
        "        print(f\"✗ {file_path} - MISSING!\")\n",
        "        missing_files.append(file_path)\n",
        "\n",
        "# Show directory structure\n",
        "print(f\"\\n📁 Current KLT directory structure:\")\n",
        "for root, dirs, files in os.walk('klt'):\n",
        "    level = root.replace('klt', '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:10]:  # Show first 10 files per directory\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 10:\n",
        "        print(f\"{subindent}... and {len(files) - 10} more files\")\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\n⚠️  Missing {len(missing_files)} critical files!\")\n",
        "    print(\"Please ensure these files are manually placed in the correct locations:\")\n",
        "    for file in missing_files:\n",
        "        print(f\"  • {file}\")\n",
        "    print(\"\\n📋 Required directory structure:\")\n",
        "    print(\"  klt/\")\n",
        "    print(\"  ├── src/          (all .c and .cu files)\")\n",
        "    print(\"  ├── include/      (all .h files)\")\n",
        "    print(\"  ├── input/        (all .pgm files)\")\n",
        "    print(\"  ├── output/       (output files)\")\n",
        "    print(\"  └── build/        (Makefiles)\")\n",
        "else:\n",
        "    print(f\"\\n🎉 All critical files found! Ready to compile!\")\n",
        "    print(f\"✅ Found {len(found_files)}/{len(critical_files)} critical files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify files and compile the complete KLT library with CUDA support\n",
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"🔍 SETTING UP KLT DIRECTORY STRUCTURE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check current directory structure and fix it\n",
        "print(\"🔍 CHECKING CURRENT DIRECTORY STRUCTURE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# List what's in the current directory\n",
        "print(\"📁 Current directory contents:\")\n",
        "for item in os.listdir('.'):\n",
        "    if os.path.isdir(item):\n",
        "        print(f\"  📁 {item}/\")\n",
        "    else:\n",
        "        print(f\"  📄 {item}\")\n",
        "\n",
        "# Check if klt directory exists and fix folder structure\n",
        "if not os.path.exists('klt'):\n",
        "    print(\"\\n📁 Creating klt directory structure...\")\n",
        "    os.makedirs('klt/src', exist_ok=True)\n",
        "    os.makedirs('klt/include', exist_ok=True)\n",
        "    os.makedirs('klt/input', exist_ok=True)\n",
        "    os.makedirs('klt/output', exist_ok=True)\n",
        "    os.makedirs('klt/build', exist_ok=True)\n",
        "    os.makedirs('klt/doc', exist_ok=True)\n",
        "    os.makedirs('klt/matlab_interface', exist_ok=True)\n",
        "    \n",
        "    # Check if folders exist at root level and move them into klt/\n",
        "    folders_to_move = ['src', 'include', 'input', 'output', 'build', 'doc', 'matlab_interface']\n",
        "    moved_folders = []\n",
        "    \n",
        "    for folder in folders_to_move:\n",
        "        if os.path.exists(folder) and os.path.isdir(folder):\n",
        "            try:\n",
        "                shutil.move(folder, f\"klt/{folder}\")\n",
        "                print(f\"✓ Moved {folder}/ → klt/{folder}/\")\n",
        "                moved_folders.append(folder)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  Could not move {folder}/: {e}\")\n",
        "    \n",
        "    if moved_folders:\n",
        "        print(f\"✅ Moved {len(moved_folders)} folders into klt/ directory\")\n",
        "    \n",
        "    # Check if files are in sample_data and move them\n",
        "    if os.path.exists('sample_data'):\n",
        "        print(\"\\n📁 Found sample_data folder - organizing files...\")\n",
        "        sample_files = os.listdir('sample_data')\n",
        "        print(f\"Found {len(sample_files)} files in sample_data/\")\n",
        "        \n",
        "        organized_count = 0\n",
        "        for filename in sample_files:\n",
        "            source_path = f\"sample_data/{filename}\"\n",
        "            \n",
        "            # Determine destination based on file extension\n",
        "            if filename.endswith('.h'):\n",
        "                dest = f\"klt/include/{filename}\"\n",
        "            elif filename.endswith('.c'):\n",
        "                dest = f\"klt/src/{filename}\"\n",
        "            elif filename.endswith('.cu'):\n",
        "                dest = f\"klt/src/{filename}\"\n",
        "            elif filename.endswith('.pgm'):\n",
        "                dest = f\"klt/input/{filename}\"\n",
        "            elif filename.startswith('Makefile') or filename.endswith('.mk'):\n",
        "                dest = f\"klt/build/{filename}\"\n",
        "            elif filename.endswith('.txt') or filename.endswith('.md'):\n",
        "                dest = f\"klt/{filename}\"\n",
        "            else:\n",
        "                dest = f\"klt/{filename}\"\n",
        "            \n",
        "            try:\n",
        "                shutil.move(source_path, dest)\n",
        "                print(f\"✓ {filename} → {dest}\")\n",
        "                organized_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  {filename} → {dest} (error: {e})\")\n",
        "        \n",
        "        print(f\"✅ Organized {organized_count}/{len(sample_files)} files!\")\n",
        "    else:\n",
        "        print(\"⚠️  No sample_data folder found.\")\n",
        "else:\n",
        "    print(\"✅ klt directory already exists\")\n",
        "    \n",
        "    # Check if klt directory is empty or has missing files\n",
        "    klt_contents = []\n",
        "    for root, dirs, files in os.walk('klt'):\n",
        "        for file in files:\n",
        "            klt_contents.append(os.path.join(root, file))\n",
        "    \n",
        "    if len(klt_contents) == 0:\n",
        "        print(\"⚠️  klt directory is empty!\")\n",
        "        print(\"🔧 Attempting to reorganize files...\")\n",
        "        \n",
        "        # Try to find files in other locations\n",
        "        if os.path.exists('sample_data'):\n",
        "            print(\"📁 Found sample_data folder - moving files to klt/...\")\n",
        "            sample_files = os.listdir('sample_data')\n",
        "            organized_count = 0\n",
        "            \n",
        "            for filename in sample_files:\n",
        "                source_path = f\"sample_data/{filename}\"\n",
        "                \n",
        "                if filename.endswith('.h'):\n",
        "                    dest = f\"klt/include/{filename}\"\n",
        "                elif filename.endswith('.c'):\n",
        "                    dest = f\"klt/src/{filename}\"\n",
        "                elif filename.endswith('.cu'):\n",
        "                    dest = f\"klt/src/{filename}\"\n",
        "                elif filename.endswith('.pgm'):\n",
        "                    dest = f\"klt/input/{filename}\"\n",
        "                elif filename.startswith('Makefile') or filename.endswith('.mk'):\n",
        "                    dest = f\"klt/build/{filename}\"\n",
        "                elif filename.endswith('.txt') or filename.endswith('.md'):\n",
        "                    dest = f\"klt/{filename}\"\n",
        "                else:\n",
        "                    dest = f\"klt/{filename}\"\n",
        "                \n",
        "                try:\n",
        "                    shutil.move(source_path, dest)\n",
        "                    print(f\"✓ {filename} → {dest}\")\n",
        "                    organized_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️  {filename} → {dest} (error: {e})\")\n",
        "            \n",
        "            print(f\"✅ Moved {organized_count}/{len(sample_files)} files to klt/\")\n",
        "    else:\n",
        "        print(f\"✅ klt directory has {len(klt_contents)} files\")\n",
        "\n",
        "# Now change to the klt directory\n",
        "if os.path.exists('klt'):\n",
        "    os.chdir('klt')\n",
        "    print(\"✅ Changed to klt directory\")\n",
        "else:\n",
        "    print(\"❌ klt directory not found!\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\n🔍 VERIFYING FILES BEFORE COMPILATION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check if all required files exist\n",
        "required_files = {\n",
        "    'CUDA Source': 'src/convolve_cuda.cu',\n",
        "    'Headers': ['include/klt.h', 'include/base.h', 'include/error.h'],\n",
        "    'CPU Sources': ['src/convolve.c', 'src/error.c', 'src/klt.c', 'src/example3.c'],\n",
        "    'Input Images': ['input/img0.pgm', 'input/img1.pgm']\n",
        "}\n",
        "\n",
        "all_files_exist = True\n",
        "for category, files in required_files.items():\n",
        "    print(f\"\\n📁 {category}:\")\n",
        "    if isinstance(files, str):\n",
        "        files = [files]\n",
        "    \n",
        "    for file_path in files:\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"  ✓ {file_path}\")\n",
        "        else:\n",
        "            print(f\"  ✗ {file_path} - MISSING!\")\n",
        "            all_files_exist = False\n",
        "\n",
        "if not all_files_exist:\n",
        "    print(f\"\\n❌ Some required files are missing!\")\n",
        "    print(\"Please re-run the upload cell and ensure all files are uploaded.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\n✅ All required files found!\")\n",
        "print(\"\\n🚀 COMPILING KLT LIBRARY WITH CUDA SUPPORT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 1: Compile the CUDA convolution program\n",
        "print(\"\\n1. Compiling CUDA convolution program...\")\n",
        "cuda_cmd = [\n",
        "    'nvcc',\n",
        "    '-O3',\n",
        "    '-std=c++11',\n",
        "    '-arch=sm_75',  # Tesla T4 has compute capability 7.5\n",
        "    '-I./include',\n",
        "    '-o', 'convolve_cuda',\n",
        "    'src/convolve_cuda.cu'\n",
        "]\n",
        "\n",
        "print(f\"Command: {' '.join(cuda_cmd)}\")\n",
        "try:\n",
        "    result = subprocess.run(cuda_cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✓ CUDA compilation successful!\")\n",
        "    if result.stdout:\n",
        "        print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"✗ CUDA compilation failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    print(f\"Standard output: {e.stdout}\")\n",
        "\n",
        "# Step 2: Compile the original KLT library (CPU version)\n",
        "print(\"\\n2. Compiling original KLT library (CPU version)...\")\n",
        "cpu_sources = [\n",
        "    'src/convolve.c',\n",
        "    'src/error.c', \n",
        "    'src/pnmio.c',\n",
        "    'src/pyramid.c',\n",
        "    'src/selectGoodFeatures.c',\n",
        "    'src/storeFeatures.c',\n",
        "    'src/trackFeatures.c',\n",
        "    'src/klt.c',\n",
        "    'src/klt_util.c',\n",
        "    'src/writeFeatures.c'\n",
        "]\n",
        "\n",
        "# Compile object files\n",
        "object_files = []\n",
        "for src in cpu_sources:\n",
        "    obj_file = src.replace('src/', 'build/').replace('.c', '.o')\n",
        "    object_files.append(obj_file)\n",
        "    \n",
        "    compile_cmd = [\n",
        "        'gcc',\n",
        "        '-c',\n",
        "        '-O3',\n",
        "        '-DNDEBUG',\n",
        "        '-I./include',\n",
        "        '-o', obj_file,\n",
        "        src\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(compile_cmd, capture_output=True, text=True, check=True)\n",
        "        print(f\"✓ Compiled {src}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ Failed to compile {src}: {e}\")\n",
        "\n",
        "# Create static library\n",
        "print(\"\\n3. Creating static library...\")\n",
        "ar_cmd = ['ar', 'rcs', 'build/libklt.a'] + object_files\n",
        "try:\n",
        "    result = subprocess.run(ar_cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✓ Static library created successfully!\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"✗ Failed to create library: {e}\")\n",
        "\n",
        "# Step 3: Compile example3 with the library\n",
        "print(\"\\n4. Compiling example3 with KLT library...\")\n",
        "example3_cmd = [\n",
        "    'gcc',\n",
        "    '-O3',\n",
        "    '-DNDEBUG',\n",
        "    '-I./include',\n",
        "    '-o', 'example3',\n",
        "    'src/example3.c',\n",
        "    '-L./build',\n",
        "    '-lklt',\n",
        "    '-lm'\n",
        "]\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(example3_cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✓ Example3 compiled successfully!\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"✗ Failed to compile example3: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "# If full compilation failed, try just the CUDA convolution\n",
        "if not os.path.exists('convolve_cuda'):\n",
        "    print(\"\\n🔄 FALLBACK: Compiling just CUDA convolution...\")\n",
        "    simple_cuda_cmd = [\n",
        "        'nvcc',\n",
        "        '-O3',\n",
        "        '-std=c++11', \n",
        "        '-arch=sm_75',\n",
        "        '-o', 'convolve_cuda',\n",
        "        'src/convolve_cuda.cu'\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(simple_cuda_cmd, capture_output=True, text=True, check=True)\n",
        "        print(\"✓ CUDA convolution compiled successfully!\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ CUDA compilation failed: {e}\")\n",
        "        print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPILATION SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check what was successfully compiled\n",
        "if os.path.exists('convolve_cuda'):\n",
        "    print(\"✓ CUDA convolution program: convolve_cuda\")\n",
        "else:\n",
        "    print(\"✗ CUDA convolution program: FAILED\")\n",
        "\n",
        "if os.path.exists('build/libklt.a'):\n",
        "    print(\"✓ KLT static library: build/libklt.a\")\n",
        "else:\n",
        "    print(\"✗ KLT static library: FAILED\")\n",
        "\n",
        "if os.path.exists('example3'):\n",
        "    print(\"✓ CPU example program: example3\")\n",
        "else:\n",
        "    print(\"✗ CPU example program: FAILED\")\n",
        "\n",
        "print(\"\\n🎯 Ready for testing!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the complete KLT algorithm with CUDA acceleration\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(\"🚀 RUNNING COMPLETE KLT ALGORITHM\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# First, run the CUDA convolution on all images\n",
        "print(\"1. Running CUDA convolution on input images...\")\n",
        "cuda_start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True, timeout=60)\n",
        "    cuda_time = time.time() - cuda_start_time\n",
        "    print(f\"✅ CUDA convolution completed in {cuda_time:.2f} seconds!\")\n",
        "    print(\"CUDA Output:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"CUDA Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"⚠️  CUDA convolution timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ CUDA convolution failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Then, run the complete KLT algorithm (example3)\n",
        "print(\"2. Running complete KLT algorithm (example3)...\")\n",
        "klt_start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run(['./example3'], capture_output=True, text=True, check=True, timeout=120)\n",
        "    klt_time = time.time() - klt_start_time\n",
        "    print(f\"✅ Complete KLT algorithm completed in {klt_time:.2f} seconds!\")\n",
        "    print(\"KLT Output:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"KLT Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"⚠️  KLT algorithm timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ KLT algorithm failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📁 CHECKING OUTPUT FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check what output files were created\n",
        "output_files = []\n",
        "if os.path.exists('output'):\n",
        "    for file in os.listdir('output'):\n",
        "        if file.endswith('.pgm') or file.endswith('.ppm') or file.endswith('.txt') or file.endswith('.ft'):\n",
        "            output_files.append(file)\n",
        "\n",
        "if output_files:\n",
        "    print(f\"✅ Found {len(output_files)} output files:\")\n",
        "    for file in sorted(output_files):\n",
        "        file_path = os.path.join('output', file)\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        print(f\"  📄 {file} ({file_size} bytes)\")\n",
        "else:\n",
        "    print(\"⚠️  No output files found in output/ directory\")\n",
        "\n",
        "print(\"\\n🎯 KLT PROCESSING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"⏱️  Total processing time: {time.time() - cuda_start_time:.2f} seconds\")\n",
        "print(\"🚀 GPU-accelerated KLT algorithm finished successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 RUN THE COMPLETE KLT ALGORITHM ON COLAB\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(\"🚀 RUNNING COMPLETE KLT ALGORITHM\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# First, run the CUDA convolution on all images\n",
        "print(\"1. Running CUDA convolution on input images...\")\n",
        "cuda_start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True, timeout=60)\n",
        "    cuda_time = time.time() - cuda_start_time\n",
        "    print(f\"✅ CUDA convolution completed in {cuda_time:.2f} seconds!\")\n",
        "    print(\"CUDA Output:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"CUDA Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"⚠️  CUDA convolution timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ CUDA convolution failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Then, run the complete KLT algorithm (example3)\n",
        "print(\"2. Running complete KLT algorithm (example3)...\")\n",
        "klt_start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run(['./example3'], capture_output=True, text=True, check=True, timeout=120)\n",
        "    klt_time = time.time() - klt_start_time\n",
        "    print(f\"✅ Complete KLT algorithm completed in {klt_time:.2f} seconds!\")\n",
        "    print(\"KLT Output:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"KLT Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"⚠️  KLT algorithm timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ KLT algorithm failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📁 CHECKING OUTPUT FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check what output files were created\n",
        "output_files = []\n",
        "if os.path.exists('output'):\n",
        "    for file in os.listdir('output'):\n",
        "        if file.endswith('.pgm') or file.endswith('.ppm') or file.endswith('.txt') or file.endswith('.ft'):\n",
        "            output_files.append(file)\n",
        "\n",
        "if output_files:\n",
        "    print(f\"✅ Found {len(output_files)} output files:\")\n",
        "    for file in sorted(output_files):\n",
        "        file_path = os.path.join('output', file)\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        print(f\"  📄 {file} ({file_size} bytes)\")\n",
        "else:\n",
        "    print(\"⚠️  No output files found in output/ directory\")\n",
        "\n",
        "print(\"\\n🎯 KLT PROCESSING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"⏱️  Total processing time: {time.time() - cuda_start_time:.2f} seconds\")\n",
        "print(\"🚀 GPU-accelerated KLT algorithm finished successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 RECOMPILE KLT WITH CORRECT PATHS\n",
        "print(\"🔧 Recompiling KLT with correct paths...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check current directory structure\n",
        "import os\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Files in current directory:\")\n",
        "for item in os.listdir('.'):\n",
        "    print(f\"  {item}\")\n",
        "\n",
        "print(\"\\nFiles in src directory:\")\n",
        "if os.path.exists('src'):\n",
        "    for item in os.listdir('src'):\n",
        "        print(f\"  src/{item}\")\n",
        "else:\n",
        "    print(\"  src/ directory not found!\")\n",
        "\n",
        "print(\"\\nFiles in include directory:\")\n",
        "if os.path.exists('include'):\n",
        "    for item in os.listdir('include'):\n",
        "        print(f\"  include/{item}\")\n",
        "else:\n",
        "    print(\"  include/ directory not found!\")\n",
        "\n",
        "# Recompile example3 with correct paths (no ../)\n",
        "try:\n",
        "    result = subprocess.run(['gcc', '-O3', '-Iinclude', '-o', 'example3', \n",
        "                            'src/example3.c', '-L.', '-lklt', '-lm'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"\\n✅ KLT recompiled successfully!\")\n",
        "    print(\"Ready to run the complete algorithm!\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"\\n❌ Recompilation failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "    print(\"Trying alternative compilation...\")\n",
        "    \n",
        "    # Try compiling with all source files (no ../)\n",
        "    try:\n",
        "        result = subprocess.run(['gcc', '-O3', '-Iinclude', '-o', 'example3', \n",
        "                                'src/example3.c', 'src/klt.c', 'src/convolve.c', \n",
        "                                'src/error.c', 'src/pnmio.c', 'src/pyramid.c',\n",
        "                                'src/selectGoodFeatures.c', 'src/storeFeatures.c',\n",
        "                                'src/trackFeatures.c', 'src/klt_util.c', 'src/writeFeatures.c',\n",
        "                                '-lm'], \n",
        "                               capture_output=True, text=True, check=True)\n",
        "        print(\"✅ Alternative compilation successful!\")\n",
        "    except subprocess.CalledProcessError as e2:\n",
        "        print(f\"❌ Alternative compilation also failed: {e2}\")\n",
        "        print(f\"Error: {e2.stderr}\")\n",
        "\n",
        "print(\"\\n🎯 Ready to run the complete KLT algorithm!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 TEST BOTH HORIZONTAL AND VERTICAL CUDA CONVOLUTION\n",
        "print(\"🚀 TESTING BOTH HORIZONTAL AND VERTICAL CUDA CONVOLUTION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Recompile the updated CUDA program with both kernels\n",
        "print(\"🔧 Recompiling CUDA program with vertical convolution...\")\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '-arch=sm_75', '-o', 'convolve_cuda', \n",
        "                            'src/convolve_cuda.cu'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"✅ CUDA program recompiled successfully!\")\n",
        "    print(\"Now testing both horizontal and vertical convolution...\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ CUDA recompilation failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Run the updated CUDA program\n",
        "print(\"🧪 Running CUDA program with both convolutions...\")\n",
        "try:\n",
        "    result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True, timeout=60)\n",
        "    print(\"✅ CUDA program completed successfully!\")\n",
        "    print(\"\\nCUDA Output:\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"\\nCUDA Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"⚠️  CUDA program timed out\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ CUDA program failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\n🎯 BOTH HORIZONTAL AND VERTICAL CONVOLUTION TESTED!\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 DEBUG CUDA SEGMENTATION FAULT\n",
        "print(\"🔧 DEBUGGING CUDA SEGMENTATION FAULT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Let's create a simple test version first\n",
        "print(\"Creating a simple CUDA test program...\")\n",
        "\n",
        "simple_cuda_code = '''\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\\\n",
        "    do { \\\\\n",
        "        cudaError_t error = call; \\\\\n",
        "        if (error != cudaSuccess) { \\\\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d - %s\\\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\\\n",
        "            exit(1); \\\\\n",
        "        } \\\\\n",
        "    } while(0)\n",
        "\n",
        "__global__ void simpleKernel(float* data, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        data[idx] = data[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Simple CUDA Test\\\\n\");\n",
        "    printf(\"===============\\\\n\");\n",
        "    \n",
        "    // Test basic CUDA functionality\n",
        "    int deviceCount;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    printf(\"CUDA devices found: %d\\\\n\", deviceCount);\n",
        "    \n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"No CUDA devices!\\\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    \n",
        "    cudaDeviceProp prop;\n",
        "    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n",
        "    printf(\"Device: %s\\\\n\", prop.name);\n",
        "    \n",
        "    // Simple memory test\n",
        "    const int n = 1024;\n",
        "    float *h_data = (float*)malloc(n * sizeof(float));\n",
        "    float *d_data;\n",
        "    \n",
        "    // Initialize host data\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_data[i] = (float)i;\n",
        "    }\n",
        "    \n",
        "    // Allocate device memory\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, n * sizeof(float)));\n",
        "    \n",
        "    // Copy to device\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, n * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    \n",
        "    // Launch kernel\n",
        "    simpleKernel<<<(n + 255) / 256, 256>>>(d_data, n);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    // Copy back\n",
        "    CUDA_CHECK(cudaMemcpy(h_data, d_data, n * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    // Check results\n",
        "    printf(\"First 5 results: \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.1f \", h_data[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    // Cleanup\n",
        "    free(h_data);\n",
        "    CUDA_CHECK(cudaFree(d_data));\n",
        "    \n",
        "    printf(\"✅ Simple CUDA test passed!\\\\n\");\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "# Write the simple test\n",
        "with open('simple_cuda_test.cu', 'w') as f:\n",
        "    f.write(simple_cuda_code)\n",
        "\n",
        "print(\"✅ Simple CUDA test program created!\")\n",
        "\n",
        "# Compile and run the simple test\n",
        "print(\"\\\\n🔧 Compiling simple CUDA test...\")\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '-arch=sm_75', '-o', 'simple_test', 'simple_cuda_test.cu'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Simple test compiled successfully!\")\n",
        "    \n",
        "    print(\"\\\\n🧪 Running simple CUDA test...\")\n",
        "    result = subprocess.run(['./simple_test'], capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Simple test passed!\")\n",
        "    print(\"Output:\")\n",
        "    print(result.stdout)\n",
        "    \n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Simple test failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\\\n🎯 Simple CUDA test completed!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 FIX THE MAIN CUDA PROGRAM\n",
        "print(\"🔧 FIXING THE MAIN CUDA PROGRAM\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Let's create a safer version of the CUDA program\n",
        "print(\"Creating a safer version of the CUDA convolution program...\")\n",
        "\n",
        "safe_cuda_code = '''\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define MAX_KERNEL_WIDTH 71\n",
        "#define CUDA_CHECK(call) \\\\\n",
        "    do { \\\\\n",
        "        cudaError_t error = call; \\\\\n",
        "        if (error != cudaSuccess) { \\\\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d - %s\\\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\\\n",
        "            exit(1); \\\\\n",
        "        } \\\\\n",
        "    } while(0)\n",
        "\n",
        "typedef struct {\n",
        "    int ncols;\n",
        "    int nrows;\n",
        "    float *data;\n",
        "} _KLT_FloatImageRec, *_KLT_FloatImage;\n",
        "\n",
        "typedef struct {\n",
        "    int width;\n",
        "    float data[MAX_KERNEL_WIDTH];\n",
        "} ConvolutionKernel;\n",
        "\n",
        "__global__ void convolveImageHorizKernel(\n",
        "    const float* input,\n",
        "    float* output,\n",
        "    const float* kernel_data,\n",
        "    int ncols,\n",
        "    int nrows,\n",
        "    int kernel_width,\n",
        "    int radius)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (col >= ncols || row >= nrows) {\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    int idx = row * ncols + col;\n",
        "    \n",
        "    if (col < radius || col >= ncols - radius) {\n",
        "        output[idx] = 0.0f;\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    float sum = 0.0f;\n",
        "    for (int k = 0; k < kernel_width; k++) {\n",
        "        int input_col = col - radius + k;\n",
        "        int input_idx = row * ncols + input_col;\n",
        "        sum += input[input_idx] * kernel_data[k];\n",
        "    }\n",
        "    \n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "__global__ void convolveImageVertKernel(\n",
        "    const float* input,\n",
        "    float* output,\n",
        "    const float* kernel_data,\n",
        "    int ncols,\n",
        "    int nrows,\n",
        "    int kernel_width,\n",
        "    int radius)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (col >= ncols || row >= nrows) {\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    int idx = row * ncols + col;\n",
        "    \n",
        "    if (row < radius || row >= nrows - radius) {\n",
        "        output[idx] = 0.0f;\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    float sum = 0.0f;\n",
        "    for (int k = 0; k < kernel_width; k++) {\n",
        "        int input_row = row - radius + k;\n",
        "        int input_idx = input_row * ncols + col;\n",
        "        sum += input[input_idx] * kernel_data[k];\n",
        "    }\n",
        "    \n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "void testConvolutions() {\n",
        "    printf(\"Testing CUDA Convolutions\\\\n\");\n",
        "    printf(\"========================\\\\n\");\n",
        "    \n",
        "    // Create test data\n",
        "    const int ncols = 64;\n",
        "    const int nrows = 64;\n",
        "    const int image_size = ncols * nrows;\n",
        "    \n",
        "    // Allocate host memory\n",
        "    float *h_input = (float*)malloc(image_size * sizeof(float));\n",
        "    float *h_output_horiz = (float*)malloc(image_size * sizeof(float));\n",
        "    float *h_output_vert = (float*)malloc(image_size * sizeof(float));\n",
        "    \n",
        "    // Initialize input with simple pattern\n",
        "    for (int i = 0; i < image_size; i++) {\n",
        "        h_input[i] = (float)(i % 256) / 255.0f;\n",
        "    }\n",
        "    \n",
        "    // Create kernel\n",
        "    ConvolutionKernel kernel;\n",
        "    kernel.width = 5;\n",
        "    for (int i = 0; i < kernel.width; i++) {\n",
        "        kernel.data[i] = 1.0f / kernel.width;  // Simple averaging kernel\n",
        "    }\n",
        "    \n",
        "    // Allocate device memory\n",
        "    float *d_input, *d_output;\n",
        "    float *d_kernel;\n",
        "    \n",
        "    CUDA_CHECK(cudaMalloc(&d_input, image_size * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_output, image_size * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_kernel, kernel.width * sizeof(float)));\n",
        "    \n",
        "    // Copy to device\n",
        "    CUDA_CHECK(cudaMemcpy(d_input, h_input, image_size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_kernel, kernel.data, kernel.width * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    \n",
        "    // Test horizontal convolution\n",
        "    dim3 blockSize(8, 8);\n",
        "    dim3 gridSize((ncols + blockSize.x - 1) / blockSize.x, \n",
        "                   (nrows + blockSize.y - 1) / blockSize.y);\n",
        "    \n",
        "    printf(\"Testing horizontal convolution...\\\\n\");\n",
        "    convolveImageHorizKernel<<<gridSize, blockSize>>>(\n",
        "        d_input, d_output, d_kernel, ncols, nrows, kernel.width, kernel.width/2);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    CUDA_CHECK(cudaMemcpy(h_output_horiz, d_output, image_size * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    // Test vertical convolution\n",
        "    printf(\"Testing vertical convolution...\\\\n\");\n",
        "    convolveImageVertKernel<<<gridSize, blockSize>>>(\n",
        "        d_input, d_output, d_kernel, ncols, nrows, kernel.width, kernel.width/2);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    CUDA_CHECK(cudaMemcpy(h_output_vert, d_output, image_size * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    // Print some results\n",
        "    printf(\"Horizontal convolution results (first 5): \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.3f \", h_output_horiz[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    printf(\"Vertical convolution results (first 5): \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.3f \", h_output_vert[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    // Cleanup\n",
        "    free(h_input);\n",
        "    free(h_output_horiz);\n",
        "    free(h_output_vert);\n",
        "    CUDA_CHECK(cudaFree(d_input));\n",
        "    CUDA_CHECK(cudaFree(d_output));\n",
        "    CUDA_CHECK(cudaFree(d_kernel));\n",
        "    \n",
        "    printf(\"✅ Both convolutions completed successfully!\\\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Safe CUDA Convolution Test\\\\n\");\n",
        "    printf(\"==========================\\\\n\");\n",
        "    \n",
        "    // Initialize CUDA\n",
        "    int deviceCount;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    \n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"No CUDA devices found!\\\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    \n",
        "    cudaDeviceProp prop;\n",
        "    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n",
        "    printf(\"Using CUDA device: %s\\\\n\", prop.name);\n",
        "    printf(\"Compute capability: %d.%d\\\\n\", prop.major, prop.minor);\n",
        "    \n",
        "    // Test convolutions\n",
        "    testConvolutions();\n",
        "    \n",
        "    printf(\"\\\\n🎉 Safe CUDA test completed successfully!\\\\n\");\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "# Write the safe test\n",
        "with open('safe_cuda_test.cu', 'w') as f:\n",
        "    f.write(safe_cuda_code)\n",
        "\n",
        "print(\"✅ Safe CUDA test program created!\")\n",
        "\n",
        "# Compile and run the safe test\n",
        "print(\"\\\\n🔧 Compiling safe CUDA test...\")\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '-arch=sm_75', '-o', 'safe_test', 'safe_cuda_test.cu'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Safe test compiled successfully!\")\n",
        "    \n",
        "    print(\"\\\\n🧪 Running safe CUDA test...\")\n",
        "    result = subprocess.run(['./safe_test'], capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Safe test passed!\")\n",
        "    print(\"Output:\")\n",
        "    print(result.stdout)\n",
        "    \n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Safe test failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\\\n🎯 Safe CUDA test completed!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 DEBUG CUDA SEGMENTATION FAULT\n",
        "print(\"🔧 DEBUGGING CUDA SEGMENTATION FAULT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Let's create a simple test version first\n",
        "print(\"Creating a simple CUDA test program...\")\n",
        "\n",
        "simple_cuda_code = '''\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\\\n",
        "    do { \\\\\n",
        "        cudaError_t error = call; \\\\\n",
        "        if (error != cudaSuccess) { \\\\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d - %s\\\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\\\n",
        "            exit(1); \\\\\n",
        "        } \\\\\n",
        "    } while(0)\n",
        "\n",
        "__global__ void simpleKernel(float* data, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        data[idx] = data[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Simple CUDA Test\\\\n\");\n",
        "    printf(\"===============\\\\n\");\n",
        "    \n",
        "    // Test basic CUDA functionality\n",
        "    int deviceCount;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    printf(\"CUDA devices found: %d\\\\n\", deviceCount);\n",
        "    \n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"No CUDA devices!\\\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    \n",
        "    cudaDeviceProp prop;\n",
        "    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n",
        "    printf(\"Device: %s\\\\n\", prop.name);\n",
        "    \n",
        "    // Simple memory test\n",
        "    const int n = 1024;\n",
        "    float *h_data = (float*)malloc(n * sizeof(float));\n",
        "    float *d_data;\n",
        "    \n",
        "    // Initialize host data\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_data[i] = (float)i;\n",
        "    }\n",
        "    \n",
        "    // Allocate device memory\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, n * sizeof(float)));\n",
        "    \n",
        "    // Copy to device\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, n * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    \n",
        "    // Launch kernel\n",
        "    simpleKernel<<<(n + 255) / 256, 256>>>(d_data, n);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    // Copy back\n",
        "    CUDA_CHECK(cudaMemcpy(h_data, d_data, n * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    // Check results\n",
        "    printf(\"First 5 results: \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.1f \", h_data[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    // Cleanup\n",
        "    free(h_data);\n",
        "    CUDA_CHECK(cudaFree(d_data));\n",
        "    \n",
        "    printf(\"✅ Simple CUDA test passed!\\\\n\");\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "# Write the simple test\n",
        "with open('simple_cuda_test.cu', 'w') as f:\n",
        "    f.write(simple_cuda_code)\n",
        "\n",
        "print(\"✅ Simple CUDA test program created!\")\n",
        "\n",
        "# Compile and run the simple test\n",
        "print(\"\\\\n🔧 Compiling simple CUDA test...\")\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '-arch=sm_75', '-o', 'simple_test', 'simple_cuda_test.cu'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Simple test compiled successfully!\")\n",
        "    \n",
        "    print(\"\\\\n🧪 Running simple CUDA test...\")\n",
        "    result = subprocess.run(['./simple_test'], capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Simple test passed!\")\n",
        "    print(\"Output:\")\n",
        "    print(result.stdout)\n",
        "    \n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Simple test failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\\\n🎯 Simple CUDA test completed!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 FIX THE MAIN CUDA PROGRAM\n",
        "print(\"🔧 FIXING THE MAIN CUDA PROGRAM\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Let's create a safer version of the CUDA program\n",
        "print(\"Creating a safer version of the CUDA convolution program...\")\n",
        "\n",
        "safe_cuda_code = '''\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define MAX_KERNEL_WIDTH 71\n",
        "#define CUDA_CHECK(call) \\\\\n",
        "    do { \\\\\n",
        "        cudaError_t error = call; \\\\\n",
        "        if (error != cudaSuccess) { \\\\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d - %s\\\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\\\n",
        "            exit(1); \\\\\n",
        "        } \\\\\n",
        "    } while(0)\n",
        "\n",
        "typedef struct {\n",
        "    int ncols;\n",
        "    int nrows;\n",
        "    float *data;\n",
        "} _KLT_FloatImageRec, *_KLT_FloatImage;\n",
        "\n",
        "typedef struct {\n",
        "    int width;\n",
        "    float data[MAX_KERNEL_WIDTH];\n",
        "} ConvolutionKernel;\n",
        "\n",
        "__global__ void convolveImageHorizKernel(\n",
        "    const float* input,\n",
        "    float* output,\n",
        "    const float* kernel_data,\n",
        "    int ncols,\n",
        "    int nrows,\n",
        "    int kernel_width,\n",
        "    int radius)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (col >= ncols || row >= nrows) {\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    int idx = row * ncols + col;\n",
        "    \n",
        "    if (col < radius || col >= ncols - radius) {\n",
        "        output[idx] = 0.0f;\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    float sum = 0.0f;\n",
        "    for (int k = 0; k < kernel_width; k++) {\n",
        "        int input_col = col - radius + k;\n",
        "        int input_idx = row * ncols + input_col;\n",
        "        sum += input[input_idx] * kernel_data[k];\n",
        "    }\n",
        "    \n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "__global__ void convolveImageVertKernel(\n",
        "    const float* input,\n",
        "    float* output,\n",
        "    const float* kernel_data,\n",
        "    int ncols,\n",
        "    int nrows,\n",
        "    int kernel_width,\n",
        "    int radius)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (col >= ncols || row >= nrows) {\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    int idx = row * ncols + col;\n",
        "    \n",
        "    if (row < radius || row >= nrows - radius) {\n",
        "        output[idx] = 0.0f;\n",
        "        return;\n",
        "    }\n",
        "    \n",
        "    float sum = 0.0f;\n",
        "    for (int k = 0; k < kernel_width; k++) {\n",
        "        int input_row = row - radius + k;\n",
        "        int input_idx = input_row * ncols + col;\n",
        "        sum += input[input_idx] * kernel_data[k];\n",
        "    }\n",
        "    \n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "void testConvolutions() {\n",
        "    printf(\"Testing CUDA Convolutions\\\\n\");\n",
        "    printf(\"========================\\\\n\");\n",
        "    \n",
        "    // Create test data\n",
        "    const int ncols = 64;\n",
        "    const int nrows = 64;\n",
        "    const int image_size = ncols * nrows;\n",
        "    \n",
        "    // Allocate host memory\n",
        "    float *h_input = (float*)malloc(image_size * sizeof(float));\n",
        "    float *h_output_horiz = (float*)malloc(image_size * sizeof(float));\n",
        "    float *h_output_vert = (float*)malloc(image_size * sizeof(float));\n",
        "    \n",
        "    // Initialize input with simple pattern\n",
        "    for (int i = 0; i < image_size; i++) {\n",
        "        h_input[i] = (float)(i % 256) / 255.0f;\n",
        "    }\n",
        "    \n",
        "    // Create kernel\n",
        "    ConvolutionKernel kernel;\n",
        "    kernel.width = 5;\n",
        "    for (int i = 0; i < kernel.width; i++) {\n",
        "        kernel.data[i] = 1.0f / kernel.width;  // Simple averaging kernel\n",
        "    }\n",
        "    \n",
        "    // Allocate device memory\n",
        "    float *d_input, *d_output;\n",
        "    float *d_kernel;\n",
        "    \n",
        "    CUDA_CHECK(cudaMalloc(&d_input, image_size * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_output, image_size * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_kernel, kernel.width * sizeof(float)));\n",
        "    \n",
        "    // Copy to device\n",
        "    CUDA_CHECK(cudaMemcpy(d_input, h_input, image_size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_kernel, kernel.data, kernel.width * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    \n",
        "    // Test horizontal convolution\n",
        "    dim3 blockSize(8, 8);\n",
        "    dim3 gridSize((ncols + blockSize.x - 1) / blockSize.x, \n",
        "                   (nrows + blockSize.y - 1) / blockSize.y);\n",
        "    \n",
        "    printf(\"Testing horizontal convolution...\\\\n\");\n",
        "    convolveImageHorizKernel<<<gridSize, blockSize>>>(\n",
        "        d_input, d_output, d_kernel, ncols, nrows, kernel.width, kernel.width/2);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    CUDA_CHECK(cudaMemcpy(h_output_horiz, d_output, image_size * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    // Test vertical convolution\n",
        "    printf(\"Testing vertical convolution...\\\\n\");\n",
        "    convolveImageVertKernel<<<gridSize, blockSize>>>(\n",
        "        d_input, d_output, d_kernel, ncols, nrows, kernel.width, kernel.width/2);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    CUDA_CHECK(cudaMemcpy(h_output_vert, d_output, image_size * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    \n",
        "    // Print some results\n",
        "    printf(\"Horizontal convolution results (first 5): \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.3f \", h_output_horiz[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    printf(\"Vertical convolution results (first 5): \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%.3f \", h_output_vert[i]);\n",
        "    }\n",
        "    printf(\"\\\\n\");\n",
        "    \n",
        "    // Cleanup\n",
        "    free(h_input);\n",
        "    free(h_output_horiz);\n",
        "    free(h_output_vert);\n",
        "    CUDA_CHECK(cudaFree(d_input));\n",
        "    CUDA_CHECK(cudaFree(d_output));\n",
        "    CUDA_CHECK(cudaFree(d_kernel));\n",
        "    \n",
        "    printf(\"✅ Both convolutions completed successfully!\\\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Safe CUDA Convolution Test\\\\n\");\n",
        "    printf(\"==========================\\\\n\");\n",
        "    \n",
        "    // Initialize CUDA\n",
        "    int deviceCount;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    \n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"No CUDA devices found!\\\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    \n",
        "    cudaDeviceProp prop;\n",
        "    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n",
        "    printf(\"Using CUDA device: %s\\\\n\", prop.name);\n",
        "    printf(\"Compute capability: %d.%d\\\\n\", prop.major, prop.minor);\n",
        "    \n",
        "    // Test convolutions\n",
        "    testConvolutions();\n",
        "    \n",
        "    printf(\"\\\\n🎉 Safe CUDA test completed successfully!\\\\n\");\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "# Write the safe test\n",
        "with open('safe_cuda_test.cu', 'w') as f:\n",
        "    f.write(safe_cuda_code)\n",
        "\n",
        "print(\"✅ Safe CUDA test program created!\")\n",
        "\n",
        "# Compile and run the safe test\n",
        "print(\"\\\\n🔧 Compiling safe CUDA test...\")\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '-arch=sm_75', '-o', 'safe_test', 'safe_cuda_test.cu'], \n",
        "                           capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Safe test compiled successfully!\")\n",
        "    \n",
        "    print(\"\\\\n🧪 Running safe CUDA test...\")\n",
        "    result = subprocess.run(['./safe_test'], capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Safe test passed!\")\n",
        "    print(\"Output:\")\n",
        "    print(result.stdout)\n",
        "    \n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Safe test failed: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "\n",
        "print(\"\\\\n🎯 Safe CUDA test completed!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the CUDA program\n",
        "print(\"Running CUDA convolution test...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(['./convolve_cuda'], capture_output=True, text=True, check=True)\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"Errors/Warnings:\")\n",
        "        print(result.stderr)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Program failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    print(f\"Standard output: {e.stdout}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Performance Comparison: CPU vs CUDA\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"PERFORMANCE COMPARISON: CPU vs CUDA KLT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test different image sizes\n",
        "test_sizes = [256, 512, 1024, 2048]\n",
        "results = []\n",
        "\n",
        "for size in test_sizes:\n",
        "    print(f\"\\nTesting {size}x{size} images...\")\n",
        "    \n",
        "    # Test CUDA convolution\n",
        "    print(\"  Running CUDA convolution...\")\n",
        "    cuda_start = time.time()\n",
        "    try:\n",
        "        result = subprocess.run(['./convolve_cuda'], \n",
        "                              capture_output=True, text=True, timeout=30)\n",
        "        cuda_time = (time.time() - cuda_start) * 1000\n",
        "        print(f\"  ✓ CUDA time: {cuda_time:.2f} ms\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"  ✗ CUDA test timed out\")\n",
        "        cuda_time = float('inf')\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ CUDA test failed: {e}\")\n",
        "        cuda_time = float('inf')\n",
        "    \n",
        "    # Test CPU KLT (if example3 works)\n",
        "    print(\"  Running CPU KLT...\")\n",
        "    cpu_start = time.time()\n",
        "    try:\n",
        "        # Create a simple test by running example3\n",
        "        result = subprocess.run(['./example3'], \n",
        "                              capture_output=True, text=True, timeout=30)\n",
        "        cpu_time = (time.time() - cpu_start) * 1000\n",
        "        print(f\"  ✓ CPU time: {cpu_time:.2f} ms\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"  ✗ CPU test timed out\")\n",
        "        cpu_time = float('inf')\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ CPU test failed: {e}\")\n",
        "        cpu_time = float('inf')\n",
        "    \n",
        "    # Calculate speedup\n",
        "    if cuda_time != float('inf') and cpu_time != float('inf') and cpu_time > 0:\n",
        "        speedup = cpu_time / cuda_time\n",
        "        print(f\"  🚀 Speedup: {speedup:.2f}x\")\n",
        "    else:\n",
        "        speedup = 0\n",
        "        print(f\"  ⚠️  Speedup: N/A\")\n",
        "    \n",
        "    results.append({\n",
        "        'size': size,\n",
        "        'cpu_time': cpu_time,\n",
        "        'cuda_time': cuda_time,\n",
        "        'speedup': speedup\n",
        "    })\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Size':<10} {'CPU (ms)':<12} {'CUDA (ms)':<12} {'Speedup':<10} {'Status':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for result in results:\n",
        "    status = \"✅ Success\" if result['speedup'] > 0 else \"❌ Failed\"\n",
        "    print(f\"{result['size']}x{result['size']:<6} \"\n",
        "          f\"{result['cpu_time']:<12.2f} \"\n",
        "          f\"{result['cuda_time']:<12.2f} \"\n",
        "          f\"{result['speedup']:<10.2f} \"\n",
        "          f\"{status:<15}\")\n",
        "\n",
        "# Calculate average speedup\n",
        "valid_speedups = [r['speedup'] for r in results if r['speedup'] > 0]\n",
        "if valid_speedups:\n",
        "    avg_speedup = sum(valid_speedups) / len(valid_speedups)\n",
        "    print(f\"\\n🎯 Average Speedup: {avg_speedup:.2f}x\")\n",
        "    print(f\"📊 Valid Tests: {len(valid_speedups)}/{len(results)}\")\n",
        "else:\n",
        "    print(\"\\n⚠️  No valid speedup measurements obtained\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
